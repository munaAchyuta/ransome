# Helpful Resources
   might be helpful for someone !!.

# USEFUL
   * to know python basics & advances : http://thomas-cokelaer.info/tutorials/python/
   * to execute notebooks from github online, replace github.com with colab.research.google.com/github on notebook url.
   * to get trained model : https://worksheets.codalab.org/worksheets/0xfa2548e70c2540ca8c2d26d7dd402f7f/
   * search google data : https://toolbox.google.com/datasetsearch
   * leader board for machine comprehension on squad data set.(https://rajpurkar.github.io/SQuAD-explorer/)
   * Career advice for recent Computer Science graduates.(https://huyenchip.com/2018/10/08/career-advice-recent-cs-graduates.html)
   * Introduction to Machine Learning for Coders: Launch.(http://www.fast.ai/2018/09/26/ml-launch/)
   * blog on progress of NLP so far.(http://blog.aylien.com/acl-2018-highlights-understanding-representations-and-evaluation-in-more-challenging-settings/)
   * Ml - shaoanlu. (https://shaoanlu.wordpress.com/2017/03/06/floydhub/)
   * understand DL basics using NLP domain.(http://nlp.seas.harvard.edu/2018/04/03/attention.html)
   * Data Science discussion forum (always updated).(https://www.researchgate.net/post/What_are_the_ML_methods_that_are_suitable_for_multi-label_classification_how_can_we_apply_these_methods_using_WEKA)
   * to download file from googleDrive use below commands.
        * wget https://raw.githubusercontent.com/pavanjadhaw/gdown.pl/master/gdown.pl && chmod u+x gdown.pl
        * ./gdown.pl "link to file" file.mp4
   * best paper awards in computer science since 1996. (https://jeffhuang.com/best_paper_awards.html?fbclid=IwAR0mQpku2c1c_qdLr3uS15aoWdcbrrEJdUE4DJSTIewWEs4hrhYXI92r3f8)
   * pytorch good sources.(https://bharathgs.github.io/Awesome-pytorch-list/)
   * software repository for Accounting and Finance.(https://sraf.nd.edu/textual-analysis/)
   * some good resources for NLP app building.(https://github.com/makcedward/nlp)
   * Discover open source deep learning code and pretrained models.(https://modelzoo.co/)
   * application development practices : The twleve factor app. (https://12factor.net/)
   * Kubernetes Best Practices. https://learnk8s.io/production-best-practices
   * Modern Software application patterns. Book(Patterns of Enterprise Application Architecture & Refactoring by Martin Fowler)
   * Install skype through Lync in Ubuntu(https://linuxsagas.digitaleagle.net/2014/01/14/using-microsoft-lync-with-ubuntu/)
   * software basics learning - https://www.tebs-lab.com/education (https://github.com/Tebs-Lab)
   * Bayesian Optimization - https://distill.pub/2020/bayesian-optimization/
   

# website/blog by individuals on ML/NLP/DL works.
   * http://ttic.uchicago.edu/~kgimpel/papers.html
   * http://www.cs.cmu.edu/~jwieting/
   * https://people.cs.umass.edu/~miyyer/
   * https://veredshwartz.blogspot.com/2018/08/deep-learning-in-nlp.html
   * https://basmaboussaha.wordpress.com/author/besmati/
   * https://pierpaolo28.github.io/blog/?source=post_page---------------------------
   * https://www.pyimagesearch.com/
   * https://ryanong.co.uk/natural-language-processing-365/      -- cool work. look for this.
   * http://gabrielilharco.com/

## Python
   * Deploy flask app with nginx using gunicorn and supervisor.(https://medium.com/ymedialabs-innovation/deploy-flask-app-with-nginx-using-gunicorn-and-supervisor-d7a93aa07c18)
   * regular expression good source.(https://www.regular-expressions.info/)(https://docs.python.org/3/library/re.html)
   
# ML
   * multi-label classification using ML models.(https://nickcdryan.com/2017/01/23/multi-label-classification-a-guided-tour/)
   * Lagrangian, duality & Convex Optimization (https://nisheethvishnoi.files.wordpress.com/2018/05/lecture12.pdf)
   * https://skymind.ai/wiki/attention-mechanism-memory-network
   * https://github.com/abhinavsagar

# NLP (Basic Features)
   * get basic featureset using stanford corenlp. https://github.com/Lynten/stanford-corenlp
   * NLP basic tools.(http://www.cs.cmu.edu/~ark/TweetNLP/)
   * text mining resource.(http://nitin-panwar.github.io/)
   * tracking NLP progress. nlpprogress.com
   * nlp made easy.(http://gluon-nlp.mxnet.io/index.html)
   * machine translation corpus.(http://www.manythings.org/anki/) (http://www.statmt.org/wmt18/)
   * Text to RDF. (https://tw.rpi.edu/web/project/gcis-imsap/NcaTxt2Rdf)(https://wiki.dbpedia.org/textext)(http://lup.lub.lu.se/search/ws/files/3053000/3191702.pdf)(https://lawlesst.github.io/notebook/rdflib-stardog.html)
   * Siri, Watson and Natural Language Processing.(http://isoft.postech.ac.kr/Course/Presentation/isoft_seminar_2014.pdf)
   * topic summarization from conversation dataset using traditional NLP and ML procedures.(https://pdfs.semanticscholar.org/8212/3b1d54436069e6e3a9462ff7d32aedf6ba58.pdf)
   * data source for NLP applications.(https://sites.google.com/site/nirajatweb/home/information-retrieval-resources)(http://text-analytics101.rxnlp.com/2011/07/user-review-datasets_20.html)
   * Automatic Structured Text Summarization with Concept Maps or ~ similar to Knowledge Graph(http://tuprints.ulb.tu-darmstadt.de/8430/1/PhDThesis_TobiasFalke.pdf)
   * NLP collective ones(https://handong1587.github.io/deep_learning/2015/10/09/nlp.html#summarization)
   * Exploiting Discourse Relations between Sentences for Text Clustering.(https://www.aclweb.org/anthology/W12-4702)
   * Entropy and Graph Based Modelling of DocumentCoherence using Discourse Entities: An Application to IR (https://arxiv.org/pdf/1507.08234v1.pdf)
   * APPLICATION OF RHETORICAL RELATIONS BETWEEN SENTENCES TO CLUSTER-BASED TEXT SUMMARIZATION(https://airccj.org/CSCP/vol5/csit53307.pdf)
   * Sentiment Analysis & Opinion Mining(https://www.cs.uic.edu/~liub/FBS/SentimentAnalysis-and-OpinionMining.pdf)
   * a benchmark comparison of state-of-the-practice sentiment analysis methods(https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-016-0085-1)
   * UniversalSentenceEncoder (https://arxiv.org/pdf/1803.11175v2.pdf)
   * Dynamic Entity Representations in Neural Language Models(https://arxiv.org/pdf/1708.00781.pdf)
   * NeuralTextGenerationinStoriesUsingEntityRepresentationsas Context (http://yangfengji.net/publication/papers/clark2018neural.pdf)
   * A discourse-aware neural network-based text model for document-level text classification(https://journals.sagepub.com/doi/abs/10.1177/0165551517743644?journalCode=jisb)
   * Automatically Evaluating Text Coherence Using Discourse Relations(http://delivery.acm.org/10.1145/2010000/2002598/p997-lin.pdf?ip=223.237.219.71&id=2002598&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1560341134_0806fa03deb3e1d386ef0b63f5b2c901)(http://dspace.dtu.ac.in:8080/jspui/bitstream/repository/14260/1/Rajiv_Final_Thesis-1.pdf)
   * Hybrid Approach for Single Text Document Summarization using Statistical and Sentiment Features(https://arxiv.org/pdf/1601.00643v1.pdf)
   * CS918: Natural Language Processing Revision Booklet(https://warwick.ac.uk/fac/sci/mathsys/people/students/2017intake/edoardo-barp/nlp_summary.pdf)
   * coreference & coherence (http://courses.washington.edu/ling571/ling571_WIN2017/slides/ling571_class16_coref_dstruct_flat.pdf)
   * Extending and Exploiting the Entity Graphfor Analysis, Classification and Visualization of German Texts(https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/konvens18_15.pdf)
   * Entropy and Graph Based Modelling of DocumentCoherence using Discourse Entities: An Application to IR (https://arxiv.org/pdf/1507.08234v1.pdf)
   * opinion mining and sentiment analysis (http://www.cs.cornell.edu/home/llee/omsa/omsa.pdf)


# NLP (Deep Learning)
   * machine comprehension (codes are available in github) (https://arxiv.org/pdf/1705.02798v6.pdf)(https://arxiv.org/pdf/1712.03556v2.pdf)(https://arxiv.org/pdf/1804.09541v1.pdf)(https://arxiv.org/pdf/1804.09541v1.pdf)(http://www.aclweb.org/anthology/P18-1158)(https://arxiv.org/pdf/1611.01603v6.pdf)
   * Dual Ask-Answer Network for Machine Reading Comprehension (https://arxiv.org/abs/1809.01997)
   * generate paraphrases(with change of syntactic structure but retaining semantic context) of a given text with given templates (http://aclweb.org/anthology/N18-1170)
   * corpus conversion service.(ingest unstructured data and get structured representation).used R-CNN & YOLOv2. (https://arxiv.org/abs/1805.09687)
   * Universal Language Model Fine-tuning for Text Classification.(https://arxiv.org/pdf/1801.06146v5.pdf)
   * BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.(https://arxiv.org/pdf/1810.04805v1.pdf)(https://www.reddit.com/r/MachineLearning/comments/9nfqxz/r_bert_pretraining_of_deep_bidirectional/)
   * Sequential Labeling with online Deep Learning (https://arxiv.org/pdf/1412.3397v3.pdf)
   * OnlineDeepLearning:LearningDeepNeuralNetworksontheFly(https://arxiv.org/pdf/1711.03705.pdf)
   * Incremental Learning in Deep Convolutional Neural NetworksUsingPartialNetworkSharing(https://arxiv.org/pdf/1712.02719.pdf)
   * Broad Learning: A paradigm shift in discriminative incremental learning(http://www.broadlearning.ai/)
   * incremental learning image classification.(https://www.microsoft.com/en-us/research/wp-content/uploads/2014/11/Error-Driven-Incremental-Learning-in-Deep-Convolutional-Neural-Network-for-Large-Scale-Image-Classification.pdf)
   * Deep contextualized word representations.(https://arxiv.org/pdf/1802.05365v2.pdf)
   * Neural Architectures for Named Entity Recognition.(https://arxiv.org/pdf/1603.01360v3.pdf)
   * Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition(https://arxiv.org/pdf/1711.07908.pdf)
   * Label Embedding for Zero-shot Fine-grained Named Entity Typing(http://sentic.net/label-embedding-for-zero-shot-named-entity-typing.pdf)
   * Streaming Word Embeddings with the Space-Saving Algorithm(https://arxiv.org/pdf/1704.07463.pdf)
   * BPEmb or Byte-Pair Encoding for a subword segmentation (https://nlp.h-its.org/bpemb/)
   * Robust Lexical Features for Improved Neural Network Named-Entity Recognition.(https://arxiv.org/pdf/1806.03489v1.pdf)(https://github.com/ghaddarAbs/NER-with-LS)
   * Opinion Mining with Deep Contextualized Embeddings (https://www.aclweb.org/anthology/N19-3006)
   * Large Scale Question Paraphrase Retrieval withSmoothed Deep Metric Learning(https://arxiv.org/pdf/1905.12786v1.pdf)
   * Variational Pretraining for Semi-supervised Text Classification (https://arxiv.org/pdf/1906.02242v1.pdf)
   * Deep Learning for Sentiment Analysis: A Survey(https://arxiv.org/pdf/1801.07883v2.pdf)
   * Parameter-Efficient Transfer Learning for NLP(https://arxiv.org/pdf/1902.00751.pdf)
   
# NN Models
   * tutorial on variational autoencoder.(https://arxiv.org/pdf/1606.05908v2.pdf) (blog - http://kvfrans.com/variational-autoencoders-explained/)
   * tutorial on generative adversarial networks.(blog - http://kvfrans.com/generative-adversial-networks-explained/)
   * object localization & detection.(https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/object_localization_and_detection.html)
   * incremental learning.(https://arxiv.org/pdf/1805.08709v1.pdf)
   * transfer learning.(https://arxiv.org/pdf/1707.01066v1.pdf)
   * buiding a basic neural conversational agent or chatbot.(https://blog.statsbot.co/chatbots-machine-learning-e83698b1a91e)(https://arxiv.org/pdf/1711.09684.pdf)(https://www.cs.mcgill.ca/~rlowe1/problem_with_neural_chatbots.pdf?utm_campaign=NLP%20News&utm_medium=email&utm_source=Revue%20newsletter)
   * A practical approach to dialogue response generation in closed domains.(https://arxiv.org/pdf/1703.09439v1.pdf)
   * seq2seq model.(https://arxiv.org/pdf/1409.3215.pdf)
   * seq2sq model for building conversational chatbot with using facebook messanger.(https://github.com/adeshpande3/Facebook-Messenger-Bot/blob/master/README.md)(https://moz.com/blog/chat-bot)(https://www.comm100.com/blog/journey-mapping-chatbot-decision-tree-from-scratch.html)(https://towardsdatascience.com/architecture-overview-of-a-conversational-ai-chat-bot-4ef3dfefd52e)(https://haptik.ai/tech/neural-conversation-model-production/)
   * deep dialogue tutorial.(https://www.csie.ntu.edu.tw/~yvchen/doc/DeepDialogue_Tutorial.pdf?utm_campaign=NLP%20News&utm_medium=email&utm_source=Revue%20newsletter)
   * cheat sheet : deep learning losses & optimizers.(https://www.hergertarian.com/cheat-sheet-deep-learning-losses-optimizers)
   * Stiffness: ANewPerspectiveonGeneralizationinNeuralNetworks(https://arxiv.org/pdf/1901.09491v1.pdf)
   * ToTuneorNottoTune? AdaptingPretrainedRepresentationstoDiverseTasks(https://arxiv.org/pdf/1903.05987v1.pdf)
   * self learning for supervised learning(https://arxiv.org/pdf/1911.04252.pdf)
